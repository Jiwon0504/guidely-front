import React, { useState, useRef } from "react";

export default function Recorder({ onTranscribedText }) {
  const [recording, setRecording] = useState(false);
  const mediaRecorderRef = useRef(null);
  const audioChunks = useRef([]);

  // ğŸ”‘ Azure Speech API ì •ë³´
  // âš ï¸ ë³´ì•ˆ ê²½ê³ : í”„ë¡œë•ì…˜ì—ì„œëŠ” API keyë¥¼ í´ë¼ì´ì–¸íŠ¸ì— ë…¸ì¶œí•˜ì§€ ë§ˆì„¸ìš”!
  // ì‹¤ì œ ë°°í¬ ì‹œì—ëŠ” ì„œë²„ ì‚¬ì´ë“œì—ì„œ ìŒì„± ì¸ì‹ì„ ì²˜ë¦¬í•˜ê±°ë‚˜ í† í° ê¸°ë°˜ ì¸ì¦ì„ ì‚¬ìš©í•˜ì„¸ìš”
  const AZURE_KEY = import.meta.env.DEV ? import.meta.env.VITE_AZURE_SPEECH_KEY : null;
  const REGION = import.meta.env.VITE_AZURE_REGION || "koreacentral";

  // í”„ë¡œë•ì…˜ì—ì„œëŠ” API key ì—†ì´ ê¸°ëŠ¥ ë¹„í™œì„±í™”
  if (!AZURE_KEY && import.meta.env.PROD) {
    console.warn('ìŒì„± ì¸ì‹ ê¸°ëŠ¥ì€ ê°œë°œ í™˜ê²½ì—ì„œë§Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.');
  }

  // ğŸ™ï¸ ë…¹ìŒ ì‹œì‘
  const startRecording = async () => {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    mediaRecorderRef.current = new MediaRecorder(stream);

    audioChunks.current = []; // ì´ˆê¸°í™”

    mediaRecorderRef.current.ondataavailable = (event) => {
      if (event.data.size > 0) {
        audioChunks.current.push(event.data);
      }
    };

    mediaRecorderRef.current.start();
    setRecording(true);
  };

  // â¹ ë…¹ìŒ ì¤‘ì§€
  const stopRecording = () => {
    mediaRecorderRef.current.stop();
    mediaRecorderRef.current.onstop = () => {
      const audioBlob = new Blob(audioChunks.current, { type: "audio/wav" });
      audioChunks.current = [];
      sendAudioToAzure(audioBlob);
    };
    setRecording(false);
  };
  // ğŸ“¡ Azure API í˜¸ì¶œ
    async function sendAudioToAzure(audioBlob) {
        // í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” API keyê°€ ì—†ìœ¼ë¯€ë¡œ ê¸°ëŠ¥ ë¹„í™œì„±í™”
        if (!AZURE_KEY) {
            console.warn('ìŒì„± ì¸ì‹ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê°œë°œ í™˜ê²½ì—ì„œë§Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.');
            onTranscribedText('ìŒì„± ì¸ì‹ì€ ê°œë°œ í™˜ê²½ì—ì„œë§Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.');
            return;
        }

        try {
        const arrayBuffer = await audioBlob.arrayBuffer();
    
        const response = await fetch(
            `https://${REGION}.stt.speech.microsoft.com/speech/recognition/conversation/cognitiveservices/v1?language=ko-KR`,
            {
            method: "POST",
            headers: {
                "Ocp-Apim-Subscription-Key": AZURE_KEY,
                "Content-Type": "audio/wav; codecs=audio/pcm; samplerate=16000",
            },
            body: arrayBuffer,
            }
        );
    
        const result = await response.json();
        console.log("ğŸ™ï¸ Azure ì¸ì‹ ê²°ê³¼ ì›ë³¸:", result);
    
        // Azureì˜ JSON êµ¬ì¡°ì— ë”°ë¼ í…ìŠ¤íŠ¸ êº¼ë‚´ê¸°
        const text = result.DisplayText || result.Text || "";
        console.log("ğŸ“Œ ìµœì¢… ì¸ì‹ëœ í…ìŠ¤íŠ¸:", text);
    
        if (onTranscribedText) {
            console.log("ğŸ“¡ App.jsxë¡œ ì „ë‹¬:", text);
            onTranscribedText(text);
        }
        } catch (error) {
        console.error("âŒ Azure STT ì˜¤ë¥˜:", error);
        }
    }
  

  return (
    <div>
      {!recording ? (
        <button 
          onClick={startRecording}
          className="p-3 bg-black/40 backdrop-blur-sm border border-gray-500/50 text-white hover:bg-black/60 transition-all duration-200 rounded-md"
        >
          ğŸ¤
        </button>
      ) : (
        <button 
          onClick={stopRecording}
          className="p-3 bg-red-500/80 backdrop-blur-sm border border-red-400/50 text-white hover:bg-red-600/80 transition-all duration-200 rounded-md"
        >
          â¹
        </button>
      )}
    </div>
  );
}